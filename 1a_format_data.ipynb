{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_to_txt(file):\n",
    "    \n",
    "    # read file\n",
    "    with open(file, encoding='utf-8', errors='ignore') as f: html_content = f.read()\n",
    "    \n",
    "    # remove credits paragraph (first p tag)\n",
    "    first_p_start_index = html_content.find('<p>')\n",
    "    first_p_end_index = html_content.find('</p>', first_p_start_index) + len('</p>')\n",
    "    html_content = html_content[:first_p_start_index] + html_content[first_p_end_index:]\n",
    "   \n",
    "    # initialize soup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # remove title\n",
    "    for title in soup.find_all('title'): title.extract()\n",
    "        \n",
    "    # replace newlines in dialogous with spaces\n",
    "    for p in soup.find_all('p'):\n",
    "        p.string = p.get_text().replace('\\n', ' ')\n",
    "        while p.get_text().count('  ') > 0: p.string = p.get_text().replace('  ', ' ')\n",
    "    \n",
    "    # get script, lowercase it\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # splitlines, join all lines, lowercase, remove weird space, replace . . . with ... for consistency\n",
    "    text = '\\n'.join(line.strip() for line in text.splitlines() if line.strip()).lower().replace(' Â  ', ' ').replace('. . .', '...')\n",
    "    # remove \"end\" from end, remove credits\n",
    "    text = text.rstrip('the end').rstrip('end').replace('opening credits', '').replace('closing credits', '').replace('ending credits', '').replace('end credits.', '')\n",
    "    # remove transcriber's note\n",
    "    text = re.sub('{transcriber.+}', '', text)\n",
    "    # add newlines before dialogue start (issue in some files)\n",
    "    text = re.sub(r' (?=[a-z]+:)', r'\\n', text)\n",
    "    # add newlines before scene descriptions (issue in some files)\n",
    "    s = re.sub(r' +(\\[.*?\\])\\n', r'\\n\\1\\n', text)\n",
    "    while s != text:\n",
    "        text = s\n",
    "        s = re.sub(r' (\\[.*?\\])\\n', r'\\n\\1\\n', text)\n",
    "    # add start and end tokens\n",
    "    text = f'<EPISODE_START>\\n{text}\\n<EPISODE_END>'\n",
    "    # remove unnecesary new lines\n",
    "    text = re.sub(r'\\n\\n+', 'r\\n', text)\n",
    "    # remove unnecessary spaces\n",
    "    text = re.sub(r'  +', r' ', text)\n",
    "    # remove everything between start token and episode name\n",
    "    text = re.sub(r'<EPISODE_START>\\n.*?the one', r'<EPISODE_START>\\nthe one', text, flags=re.DOTALL)\n",
    "    # replace shorter names which are in some files\n",
    "    text = text.replace('chan: ', 'chandler: ').replace('mnca: ', 'monica: ').replace('phoe: ', 'phoebe: ').replace('rach: ', 'rachel: ')\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all .html to .txt\n",
    "read_dir = './data/raw/scripts'\n",
    "write_dir = './data/interim/scripts'\n",
    "for filename in os.listdir(read_dir):\n",
    "    with open(f'{write_dir}/{filename.replace('.html','.txt')}', 'w', encoding='utf-8') as f: f.write(html_to_txt(f'{read_dir}/{filename}')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['0210.txt', '0602.txt', '0613.txt', '0704.txt'], ['1007.txt'], ['1004.txt'])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix these manually\n",
    "l,l1,l2 = [],[],[]\n",
    "for filename in os.listdir(write_dir):\n",
    "    with open(f'{write_dir}/{filename}', encoding='utf-8') as f:\n",
    "        t = f.read()\n",
    "        if t.count(\"credits\")>0: l.append(filename)\n",
    "        if t.count(\" ]\")>0: l1.append(filename)\n",
    "        if t.count(\"[\\n\")>0: l2.append(filename)\n",
    "# remove text between start token and episode name: s10e1718\n",
    "l,l1,l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0203.txt', 2614),\n",
       " ('0206.txt', 2812),\n",
       " ('0108.txt', 2902),\n",
       " ('0114.txt', 2908),\n",
       " ('0215.txt', 2977),\n",
       " ('0121.txt', 2981),\n",
       " ('0205.txt', 2994),\n",
       " ('0202.txt', 3000),\n",
       " ('0201.txt', 3070),\n",
       " ('0204.txt', 3084)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {}\n",
    "for filename in os.listdir(write_dir):\n",
    "    with open(f'{write_dir}/{filename}', encoding='utf-8') as f: \n",
    "        d[filename] = len(f.read().split())\n",
    "(sorted(d.items(), key=lambda item: item[1]))[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
