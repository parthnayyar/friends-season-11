{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_to_txt(file):\n",
    "    \n",
    "    # read file\n",
    "    with open(file, encoding='utf-8', errors='ignore') as f: html_content = f.read()\n",
    "    \n",
    "    # remove credits paragraph (first p tag)\n",
    "    first_p_start_index = html_content.find('<p>')\n",
    "    first_p_end_index = html_content.find('</p>', first_p_start_index) + len('</p>')\n",
    "    html_content = html_content[:first_p_start_index] + html_content[first_p_end_index:]\n",
    "\n",
    "    html_content = re.sub('<font.*?>', '', html_content, flags=re.DOTALL)\n",
    "    html_content = re.sub('</font>', '', html_content)\n",
    "    html_content = re.sub('<b>', '', html_content)\n",
    "    html_content = re.sub('</b>', '', html_content)\n",
    "    html_content = re.sub('<strong>', '', html_content)\n",
    "    html_content = re.sub('</strong>', '', html_content)\n",
    "   \n",
    "    # initialize soup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # remove title\n",
    "    for title in soup.find_all('title'): title.extract()\n",
    "        \n",
    "    # replace newlines in dialogous with spaces\n",
    "    for p in soup.find_all('p'):\n",
    "        p.string = p.get_text().replace('\\n', ' ')\n",
    "        while p.get_text().count('  ') > 0: p.string = p.get_text().replace('  ', ' ')\n",
    "    \n",
    "    # get script, lowercase it\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # splitlines, join all lines, lowercase, remove weird space, replace . . . with ... for consistency\n",
    "    text = '\\n'.join(line.strip() for line in text.splitlines() if line.strip()).lower().replace(' Â  ', ' ').replace('. . .', '...')\n",
    "    # remove \"end\" from end, remove credits\n",
    "    text = text.rstrip('the end').rstrip('end').replace('opening credits', '').replace('closing credits', '').replace('ending credits', '').replace('end credits.', '')\n",
    "    # remove transcriber's note\n",
    "    text = re.sub('{transcriber.+}', '', text)\n",
    "\n",
    "    if text.count('\\n')<50: \n",
    "        # add newlines before dialogue start (issue in some files)\n",
    "        text = re.sub(r' (?=[a-z]+:)', r'\\n', text)\n",
    "        # add newlines before scene descriptions (issue in some files)\n",
    "        s = re.sub(r' +(\\[.*?\\])\\n', r'\\n\\1\\n', text)\n",
    "        while s != text:\n",
    "            text = s\n",
    "            s = re.sub(r' (\\[.*?\\])\\n', r'\\n\\1\\n', text)\n",
    "    # add start and end tokens\n",
    "    text = f'<EPISODE_START>\\n{text}\\n<EPISODE_END>'\n",
    "    # remove unnecesary new lines\n",
    "    text = re.sub(r'\\n\\n+', 'r\\n', text)\n",
    "    # remove unnecessary spaces\n",
    "    text = re.sub(r'  +', r' ', text)\n",
    "    # remove everything between start token and episode name\n",
    "    text = re.sub(r'<EPISODE_START>\\n.*?the one', r'<EPISODE_START>\\nthe one', text, flags=re.DOTALL)\n",
    "    # replace shorter names which are in some files\n",
    "    text = text.replace('chan: ', 'chandler: ').replace('mnca: ', 'monica: ').replace('phoe: ', 'phoebe: ').replace('rach: ', 'rachel: ')\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all .html to .txt\n",
    "read_dir = './data/raw/scripts'\n",
    "write_dir = './data/interim/scripts'\n",
    "for filename in os.listdir(read_dir):\n",
    "    with open(f'{write_dir}/{filename.replace('.html','.txt')}', 'w', encoding='utf-8') as f: f.write(html_to_txt(f'{read_dir}/{filename}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], ['1004.txt', '1007.txt'], ['1004.txt', '1007.txt'], [], [])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix these manually\n",
    "l,l1,l2,l3,l4 = [],[],[],[],[]\n",
    "for filename in os.listdir(write_dir):\n",
    "    with open(f'{write_dir}/{filename}', encoding='utf-8') as f:\n",
    "        t = f.read()\n",
    "        if t.count(\"credits\")>0: l.append(filename)\n",
    "        if t.count(\" ]\")>0: l1.append(filename)\n",
    "        if t.count(\"[\\n\")>0: l2.append(filename)\n",
    "        if t.count(\"\\n]\")>0: l2.append(filename)\n",
    "        if t.count(\" ]\")>0: l2.append(filename)\n",
    "# remove text between start token and episode name: s10e1718\n",
    "l,l1,l2,l3,l4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0819.txt', (7, '<EPISODE_END>')),\n",
       " ('0208.txt', (6, '<EPISODE_END>')),\n",
       " ('0620.txt', (6, '<EPISODE_END>')),\n",
       " ('0112.txt', (4, '<EPISODE_END>')),\n",
       " ('0118.txt', (4, '<EPISODE_END>')),\n",
       " ('0510.txt', (4, '<EPISODE_END>')),\n",
       " ('1011.txt', (4, '<EPISODE_END>')),\n",
       " ('0316.txt', (3, '<EPISODE_END>')),\n",
       " ('0511.txt', (3, '<EPISODE_END>')),\n",
       " ('0523.txt', (3, '<EPISODE_END>')),\n",
       " ('0612.txt', (3, '<EPISODE_END>')),\n",
       " ('0801.txt', (3, '<EPISODE_END>')),\n",
       " ('0906.txt', (3, '<EPISODE_END>')),\n",
       " ('0919.txt', (3, '<EPISODE_END>')),\n",
       " ('0920.txt', (3, '<EPISODE_END>')),\n",
       " ('0101.txt', (2, '<EPISODE_END>')),\n",
       " ('0102.txt', (2, '<EPISODE_END>')),\n",
       " ('0103.txt', (2, '<EPISODE_END>')),\n",
       " ('0104.txt', (2, '<EPISODE_END>')),\n",
       " ('0106.txt', (2, '<EPISODE_END>'))]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {}\n",
    "for filename in os.listdir(write_dir):\n",
    "    with open(f'{write_dir}/{filename}', encoding='utf-8') as f: \n",
    "        lines = f.read().split('\\n')\n",
    "        m = 0\n",
    "        l = None\n",
    "        for line in lines:\n",
    "            c = line.count(':')\n",
    "            if c>m: \n",
    "                m = c\n",
    "                l = line\n",
    "        d[filename] = (m, line)\n",
    "sorted(d.items(), key=lambda item: item[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfilename = './data/interim/all.txt'\n",
    "with open(outfilename, 'w', encoding='utf-8') as outfile:\n",
    "    for filename in os.listdir(write_dir):\n",
    "        if filename != 'all.txt':\n",
    "            with open(f'{write_dir}/{filename}', encoding='utf-8') as infile:\n",
    "                outfile.write(infile.read())\n",
    "                outfile.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
