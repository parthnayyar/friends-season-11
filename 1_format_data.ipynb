{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_to_txt(file):\n",
    "    \n",
    "    # read file\n",
    "    with open(file, encoding='utf-8', errors='ignore') as f: html_content = f.read()\n",
    "    \n",
    "    # remove credits paragraph (first p tag)\n",
    "    first_p_start_index = html_content.find('<p>')\n",
    "    first_p_end_index = html_content.find('</p>', first_p_start_index) + len('</p>')\n",
    "    html_content = html_content[:first_p_start_index] + html_content[first_p_end_index:]\n",
    "\n",
    "    html_content = re.sub('<font.*?>', '', html_content, flags=re.DOTALL)\n",
    "    html_content = re.sub('</font>', '', html_content)\n",
    "    html_content = re.sub('<b>', '', html_content)\n",
    "    html_content = re.sub('</b>', '', html_content)\n",
    "    html_content = re.sub('</b>', '', html_content)\n",
    "   \n",
    "    # initialize soup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # remove title\n",
    "    for title in soup.find_all('title'): title.extract()\n",
    "        \n",
    "    # replace newlines in dialogous with spaces\n",
    "    for p in soup.find_all('p'):\n",
    "        p.string = p.get_text().replace('\\n', ' ')\n",
    "        while p.get_text().count('  ') > 0: p.string = p.get_text().replace('  ', ' ')\n",
    "    \n",
    "    # get script, lowercase it\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # splitlines, join all lines, lowercase, remove weird space, replace . . . with ... for consistency\n",
    "    text = '\\n'.join(line.strip() for line in text.splitlines() if line.strip()).lower().replace(' Â  ', ' ').replace('. . .', '...')\n",
    "    # remove \"end\" from end, remove credits\n",
    "    text = text.rstrip('the end').rstrip('end').replace('opening credits', '').replace('closing credits', '').replace('ending credits', '').replace('end credits.', '')\n",
    "    # remove transcriber's note\n",
    "    text = re.sub('{transcriber.+}', '', text)\n",
    "\n",
    "    if text.count('\\n')<50: \n",
    "        # add newlines before dialogue start (issue in some files)\n",
    "        text = re.sub(r' (?=[a-z]+:)', r'\\n', text)\n",
    "        # add newlines before scene descriptions (issue in some files)\n",
    "        s = re.sub(r' +(\\[.*?\\])\\n', r'\\n\\1\\n', text)\n",
    "        while s != text:\n",
    "            text = s\n",
    "            s = re.sub(r' (\\[.*?\\])\\n', r'\\n\\1\\n', text)\n",
    "    # add start and end tokens\n",
    "    text = f'<EPISODE_START>\\n{text}\\n<EPISODE_END>'\n",
    "    # remove unnecesary new lines\n",
    "    text = re.sub(r'\\n\\n+', 'r\\n', text)\n",
    "    # remove unnecessary spaces\n",
    "    text = re.sub(r'  +', r' ', text)\n",
    "    # remove everything between start token and episode name\n",
    "    text = re.sub(r'<EPISODE_START>\\n.*?the one', r'<EPISODE_START>\\nthe one', text, flags=re.DOTALL)\n",
    "    # replace shorter names which are in some files\n",
    "    text = text.replace('chan: ', 'chandler: ').replace('mnca: ', 'monica: ').replace('phoe: ', 'phoebe: ').replace('rach: ', 'rachel: ')\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all .html to .txt\n",
    "read_dir = './data/raw/scripts'\n",
    "write_dir = './data/interim/scripts'\n",
    "for filename in os.listdir(read_dir):\n",
    "    with open(f'{write_dir}/{filename.replace('.html','.txt')}', 'w', encoding='utf-8') as f: f.write(html_to_txt(f'{read_dir}/{filename}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['0210.txt', '0602.txt', '0613.txt', '0704.txt'],\n",
       " ['0909.txt', '1004.txt', '1007.txt'],\n",
       " ['0909.txt', '1004.txt', '1007.txt'],\n",
       " [],\n",
       " [])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix these manually\n",
    "l,l1,l2,l3,l4 = [],[],[],[],[]\n",
    "for filename in os.listdir(write_dir):\n",
    "    with open(f'{write_dir}/{filename}', encoding='utf-8') as f:\n",
    "        t = f.read()\n",
    "        if t.count(\"credits\")>0: l.append(filename)\n",
    "        if t.count(\" ]\")>0: l1.append(filename)\n",
    "        if t.count(\"[\\n\")>0: l2.append(filename)\n",
    "        if t.count(\"\\n]\")>0: l2.append(filename)\n",
    "        if t.count(\" ]\")>0: l2.append(filename)\n",
    "# remove text between start token and episode name: s10e1718\n",
    "l,l1,l2,l3,l4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0423.txt', 12193),\n",
       " ('0923-0924.txt', 8494),\n",
       " ('0523.txt', 8292),\n",
       " ('0913.txt', 8031),\n",
       " ('0624.txt', 7669),\n",
       " ('1017-1018.txt', 7321),\n",
       " ('0615-0616.txt', 7287),\n",
       " ('0723.txt', 6984),\n",
       " ('0911.txt', 6979),\n",
       " ('0823.txt', 6739),\n",
       " ('0212-0213.txt', 6316),\n",
       " ('0906.txt', 5496),\n",
       " ('1012.txt', 5122),\n",
       " ('0716.txt', 4941),\n",
       " ('0117.txt', 4900),\n",
       " ('1001.txt', 4701),\n",
       " ('0522.txt', 4636),\n",
       " ('1011.txt', 4635),\n",
       " ('0715.txt', 4630),\n",
       " ('0713.txt', 4625)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "d = {}\n",
    "for filename in os.listdir(write_dir):\n",
    "    with open(f'{write_dir}/{filename}', encoding='utf-8') as f: \n",
    "        d[filename] = len(f.read().split())\n",
    "sorted(d.items(), key=lambda item: item[1], reverse=True)[:20]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfilename = './data/interim/all.txt'\n",
    "with open(outfilename, 'w', encoding='utf-8') as outfile:\n",
    "    for filename in os.listdir(write_dir):\n",
    "        if filename != 'all.txt':\n",
    "            with open(f'{write_dir}/{filename}', encoding='utf-8') as infile:\n",
    "                outfile.write(infile.read())\n",
    "                outfile.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
